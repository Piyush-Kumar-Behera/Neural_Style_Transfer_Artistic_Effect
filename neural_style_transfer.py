# -*- coding: utf-8 -*-
"""Neural_Style_Transfer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kmeB_UMO-njKht0hGM5_8df6NdmJYhb3
"""

!pip install scipy==1.1.0

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x

import os
import sys
import scipy.io 
import scipy.misc
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import cv2
from PIL import Image

scipy.__version__

MEANS = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))

def reshape_and_normalize_image(image):
  image = np.reshape(image, ((1,) + image.shape))
  image = image - MEANS
  return image

def denormalize(image):
  image_mean = image + MEANS
  return image_mean

def generate_noise_image(content_image, noise_ratio = 0.6):
  noise_image = np.random.uniform(-20,20, (1,300,400,3)).astype('float32')
  input_image = noise_image * noise_ratio + content_image * (1 - noise_ratio)
  return input_image

def create_model(path = 'drive/My Drive/VGG 19 trained model/imagenet-vgg-verydeep-19.mat'):
  """
  This function is built to load the tensorflow model of VGG 19 using pretrained weights.
  """

  input_height = 300
  input_width = 400
  color_channels = 3

  vgg19 = scipy.io.loadmat(path)
  vgg19_layers = vgg19['layers']

  def weights1(layer):

    Wb = vgg19_layers[0][layer][0][0][0]

    W = Wb[0][0]
    b = Wb[0][1]
    layer_name = vgg19_layers[0][layer][0][0][3][0]

    return W, b, layer_name

  def relu1(convlayer):
    return tf.nn.relu(convlayer)

  def conv2d1(prev_layer, layer):
    W,b,layer_name = weights1(layer = layer)
    W = tf.constant(W)
    b = tf.constant(b)

    return tf.nn.conv2d(prev_layer, filter = W, strides = [1,1,1,1], padding = 'SAME') + b, layer_name
  
  def conv_layer(prev_layer, layer):
    conv2d, layer_name = conv2d1(prev_layer, layer)
    return relu1(conv2d), layer_name

  def avgpool1(prev_layer):
    return tf.nn.avg_pool(prev_layer, ksize=[1,2,2,1], strides = [1,2,2,1], padding = 'SAME')

  #Constructing VGG19 graph

  graph = {}
  graph['input'] = tf.Variable(np.zeros((1, input_height, input_width, color_channels)), dtype = 'float32')
  
  out,layer_name = conv_layer(graph['input'], 0)
  graph[layer_name] = out
  out,layer_name = conv_layer(graph[layer_name], 2)
  graph[layer_name] = out
  graph['avgpool1'] = avgpool1(graph[layer_name])

  out,layer_name = conv_layer(graph['avgpool1'], 5)
  graph[layer_name] = out
  out,layer_name = conv_layer(graph[layer_name], 7)
  graph[layer_name] = out
  graph['avgpool2'] = avgpool1(graph[layer_name])

  out,layer_name = conv_layer(graph['avgpool2'], 10)
  graph[layer_name] = out
  out,layer_name = conv_layer(graph[layer_name], 12)
  graph[layer_name] = out
  out,layer_name = conv_layer(graph[layer_name], 14)
  graph[layer_name] = out
  out,layer_name = conv_layer(graph[layer_name], 16)
  graph[layer_name] = out
  graph['avgpool3'] = avgpool1(graph[layer_name])

  out,layer_name = conv_layer(graph['avgpool3'], 19)
  graph[layer_name] = out
  out,layer_name = conv_layer(graph[layer_name], 21)
  graph[layer_name] = out
  out,layer_name = conv_layer(graph[layer_name], 23)
  graph[layer_name] = out
  out,layer_name = conv_layer(graph[layer_name], 25)
  graph[layer_name] = out
  graph['avgpool4'] = avgpool1(graph[layer_name])

  out,layer_name = conv_layer(graph['avgpool4'], 28)
  graph[layer_name] = out
  out,layer_name = conv_layer(graph[layer_name], 30)
  graph[layer_name] = out
  out,layer_name = conv_layer(graph[layer_name], 32)
  graph[layer_name] = out
  out,layer_name = conv_layer(graph[layer_name], 34)
  graph[layer_name] = out
  graph['avgpool5'] = avgpool1(graph[layer_name])


  return graph

def compute_content_cost(a_C, a_G):
  m, n_H, n_W, n_C = a_G.get_shape().as_list()
  J_content = tf.reduce_sum(tf.square(a_C - a_G)/(4 * n_H * n_W * n_C))
  return J_content

def gram_matrix(A):
  GA = tf.matmul(A, tf.transpose(A))
  return GA

def compute_style_cost_sl(a_S,a_G):
  m, n_H, n_W, n_C = a_G.get_shape().as_list()
  a_S = tf.transpose(tf.reshape(a_S, shape = [-1, n_C]), perm = [1,0])
  a_G = tf.transpose(tf.reshape(a_G, shape = [-1, n_C]), perm = [1,0])

  GS = gram_matrix(a_S)
  GG = gram_matrix(a_G)

  J_style_layer = tf.reduce_sum(tf.divide(tf.square(GS - GG),(4 * (n_C ** 2) * ((n_H * n_W) ** 2))))

  return J_style_layer

def compute_style_cost(model, Style_Layers):
  J_style = 0
  for layer_name, coeff in Style_Layers:
    out = model[layer_name]
    a_S = sess.run(out)
    a_G = out

    J_style_layer = compute_style_cost_sl(a_S,a_G)

    J_style += coeff * J_style_layer

  return J_style

def total_cost(J_content, J_style, alpha = 10, beta = 40):
  J = alpha * J_content + beta * J_style
  return J

Style_Layers =[
    ('conv1_1', 0.2),
    ('conv2_1', 0.2),
    ('conv3_1', 0.2),
    ('conv4_1', 0.2),
    ('conv5_1', 0.2)]

tf.reset_default_graph()
sess = tf.InteractiveSession()

content_image_path = 'drive/My Drive/Neural_Style_Transfer_Images/alpha3.jpeg'

style_image_path = 'drive/My Drive/Neural_Style_Transfer_Images/beta2.jpeg'

content_image = scipy.misc.imread(content_image_path)
plt.imshow(content_image)
content_image = cv2.resize(content_image, dsize = (400,300),interpolation = cv2.INTER_AREA)
print(np.mean(content_image))
content_image = reshape_and_normalize_image(content_image)
print(np.min(content_image))

style_image = scipy.misc.imread(style_image_path)
plt.imshow(style_image)
style_image = cv2.resize(style_image, dsize = (400,300),interpolation = cv2.INTER_AREA)
style_image = reshape_and_normalize_image(style_image)

generated_image = generate_noise_image(content_image, noise_ratio=0.6)

model = create_model()

sess.run(model['input'].assign(content_image))
out = model['conv4_2']
a_C = sess.run(out)
a_G = out
J_content = compute_content_cost(a_C, a_G)

sess.run(model['input'].assign(style_image))
J_style = compute_style_cost(model, Style_Layers)

J = total_cost(J_content, J_style, alpha = 10, beta = 40)

optimizer = tf.train.AdamOptimizer(2.0)
train = optimizer.minimize(J)

def model_nst(sess, input_image, num_iterations = 400):
  sess.run(tf.global_variables_initializer())
  sess.run(model['input'].assign(input_image))

  for i in range(num_iterations):
    sess.run(train)
    generated_image = sess.run(model['input'])

    if i%100 == 0:
      Jt, Jc, Js = sess.run([J, J_content, J_style])
      print("Iteration " + str(i) + " :")
      print("total cost = " + str(Jt))
      print("content cost = " + str(Jc))
      print("style cost = " + str(Js))

  return generated_image

generated_image = model_nst(sess, generated_image, 500)

final = denormalize(generated_image)
min_gm = np.min(generated_image)
max_gm = np.max(generated_image)
generated_image_new = generated_image - min_gm
generated_image_new1 = (generated_image_new ) / (max_gm - min_gm)
plt.imshow(generated_image_new1[0])

content_image = scipy.misc.imread(content_image_path)
plt.imshow(content_image)

style_image = scipy.misc.imread(style_image_path)
plt.imshow(style_image)

